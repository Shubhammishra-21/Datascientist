{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import __future__\n",
    "pprint(__future__.all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from__future import print_function\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import os\n",
    "\n",
    "num_classes = 81\n",
    "img_rows,img_cols = 32,32\n",
    "batch_size = 16\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = './train'\n",
    "validation_data_dir = './validation'\n",
    "\n",
    "\n",
    "#Lets use same Data Augementation\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "       rescale=1/255,\n",
    "    rotation_range = 30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows,img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Define Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',\n",
    "                input_shape=(img_rows,img_cols,3)))\n",
    "model.add(Activation,('relu'))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation,('relu'))\n",
    "model.add(Maxpooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Maxpooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,show_shapes=True,show_layers_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLRonPlateau\n",
    "checkpoint=ModelCheckpoint(r\"C:\\Users\\Shubham\\Desktop\\hdf5_data.h5\")\n",
    "                           monitor=\"val_loss\",\n",
    "                           mode=\"min\",\n",
    "                 save_best_only = True,\n",
    "                   verbose       = 1)\n",
    "                \n",
    "                \n",
    "                earlystop = earlystopping(monitor = 'val_loss'\n",
    "                                         min_delta= 0,\n",
    "                                         patience = 3,\n",
    "                                         verbose  = 1,\n",
    "                                         restore_best_weight = True)\n",
    "reduce_lr = reduceLRonPlateau(monitor='val_loss',\n",
    "                               factor = 0.2,\n",
    "                              Patience = 3,\n",
    "                              verbose  = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy')\n",
    "               optimizers = Adam(learning_rate=0.01\n",
    "                metrix     = ['accuracy'])        \n",
    "    \n",
    "nb_train_samples = 12333\n",
    "nb_validation_samples = 5632\n",
    "epochs=20\n",
    "history = model.fit_generator(\n",
    "   train_generator,\n",
    "    step_per_epoch = nb_train_samples//batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display our Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "img_rows,img_height,img_dept=32,32,3\n",
    "model=load_model(r\"C:\\Users\\Shubham\\Desktop\\hdf5_data.h5\")\n",
    "class_labels = validation_generator,class_indices\n",
    "class_labels=(v:k for k, v in class_labels,items())\n",
    "classes=lists(class_labels.values())\n",
    "nb_train_samples=12332\n",
    "nb_validation_samples=5632\n",
    "\n",
    "Y_predict=model.predict_generator(validation_generator,nb_validation_samples//batch_size+1)\n",
    "y_predict=np.argmax(Y_predict,axis=1)\n",
    "\n",
    "target_names=list(class_labels.values())\n",
    "plot.figure(figuresize=(20,20))\n",
    "cnf_matrix=confusion_matrix(validation_generator,classes,y_predict)\n",
    "\n",
    "plt.imshow(cnf_matrix,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks=np.arrange(len(classes))\n",
    " =plt.xticks(tick_marks,classes,rotation=90)\n",
    "-\n",
    " = plt.yticks(tick_marks,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import images\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import os import listdir\n",
    "from os.path import isfile,join\n",
    "import re\n",
    "\n",
    "def draw_test(name,pred,im,true_label):\n",
    "    BLACK=[0,0,0]\n",
    "    expanded_image=cv2.copyMakeBorder(im,160,0,0,500,cv2,Border_Constat,value=BLACK)\n",
    "    cv2.putText(expanded_image,\"Predicted -\"+pred(20,60)cv2.font_hershey,SIMPLEX,1,(0,255,0),2 )\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "    \n",
    "def getRandomImage(Path,img_width,img_height):\n",
    "    folders=list(filter(lambda x:os.path.isdir(os.path.join(path,x)),os.listdir(path)))\n",
    "    randomdir=np.random.randint(0,len(folders))\n",
    "    path_class=folders[random_directory]\n",
    "    file_path=path+path_class\n",
    "    file_names=[f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
    "    random_file_index=np.random.randint(0,len(file_names))\n",
    "    image_name=file_names[random_file_index]\n",
    "    final_path=file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path,target_size = (img_width,img_height)),final_path,path_class\n",
    "img_width,img_height=32,32\n",
    "files=[]\n",
    "predictions=[]\n",
    "true_labels=[]\n",
    "\n",
    "for i in range(0,100):\n",
    "    path=\"./validation/\"\n",
    "    img,final_path,true_label = getrandomimage(path,img_width,img_height)\n",
    "    file.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x=x*1./255\n",
    "    x=np.expend_dims(x,axis=0)\n",
    "    images=np.vstack([x])\n",
    "    classes=model.predict_classes(images,batch_size=10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "    for i in range(0,len(files)):\n",
    "        image=cv2.imread((files[i]))\n",
    "        draw_test(\"Prediction\",class_labels[predictions[i][0]],image,true_labels[i])\n",
    "        cv2.waitkey(0)\n",
    "        \n",
    "cv2.destroyAllwindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
